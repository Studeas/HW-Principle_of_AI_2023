{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Source Code\n",
    "**Studeas 2023 fall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集预处理\n",
    "为了便于使用pytorch进行后续计算与训练，需要预处理数据集（图片、标签文件）。class CustomDataset继承torch.utils.data中的Dataset类，允许我们处理自定义数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 50000\n",
      "Image 0: Label - 1\n",
      "Image 1: Label - 1\n",
      "Image 2: Label - 0\n",
      "Image 3: Label - 0\n",
      "Image 4: Label - 0\n",
      "Image 5: Label - 1\n",
      "Image 6: Label - 0\n",
      "Image 7: Label - 1\n",
      "Image 8: Label - 0\n",
      "Image 9: Label - 0\n"
     ]
    }
   ],
   "source": [
    "# 自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    # 初始化数据集方法\n",
    "    def __init__(self, root_dir, csv_file, characteristics, num_classes, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.characteristics = characteristics\n",
    "        self.num_classes = num_classes\n",
    "        self.characteristic_indices = self._get_characteristic_indices(csv_file)\n",
    "        self.labels = self._load_labels_from_csv(csv_file)\n",
    "\n",
    "    # 获取指定索引的图片和标签\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = sorted(os.listdir(self.root_dir))[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[img_name]\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    # 求size of dataset的方法\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_dir))\n",
    "\n",
    "    # 获取我们关心的特征列表在csv文件中的索引\n",
    "    def _get_characteristic_indices(self, csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        columns = df.columns[1:].tolist()\n",
    "        indices = [columns.index(c) for c in self.characteristics[:self.num_classes - 1]]\n",
    "        return indices\n",
    "\n",
    "    # 从csv文件中加载标签\n",
    "    def _load_labels_from_csv(self, csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        labels = {row[0]: self._determine_label(row[1:].values.tolist()) for _, row in df.iterrows()}\n",
    "        return labels\n",
    "\n",
    "    # 根据特征确定标签\n",
    "    def _determine_label(self, label_vector):\n",
    "        for rank, i in enumerate(self.characteristic_indices):\n",
    "            if label_vector[i] == 1:\n",
    "                return rank\n",
    "        return self.num_classes - 1\n",
    " \n",
    "# 数据格式调整\n",
    "transform_pipeline = transforms.Compose([\n",
    "    # reshape/resize\n",
    "    transforms.Resize((224, 224)), \n",
    "    # 转化为张量\n",
    "    transforms.ToTensor(), \n",
    "    # 正则化\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "\n",
    "# 实例化，得到dataset\n",
    "dataset = CustomDataset(\n",
    "    # 图片文件夹、标签文件地址\n",
    "    root_dir='./data_face_imgs/images',\n",
    "    csv_file='./data_face_imgs/anno.csv',\n",
    "    # 二分类问题，是否微笑\n",
    "    characteristics=['Smiling', 'Others'],\n",
    "    num_classes=2,\n",
    "    # 五分类问题，发色分类\n",
    "    #characteristics=['Black_Hair','Blond_Hair','Brown_Hair','Gray_Hair','Others'],\n",
    "    #num_classes=5,\n",
    "    # 格式调整\n",
    "    transform=transform_pipeline\n",
    ")\n",
    "\n",
    "# 打印数据集前10项，包含图片编号和对应标签值（模块功能测试）\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "for i in range(10):\n",
    "    image, label = dataset[i]\n",
    "    print(f\"Image {i}: Label - {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义一个卷积神经网络CNN\n",
    "CNN包含两个卷积池化层和两个全连接层。模型并不复杂，但是足够处理本次图像分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    # 初始化方法，CNN包含两个卷积池化层和两个全连接层\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        # 卷积层1，输入通道3，输出通道16，卷积核3*3\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # 最大池化层，窗口大小和步长都是2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # 卷积层2，输入通道16，输出通道32，卷积核3*3\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # 全连接层1\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 512)  \n",
    "        # 全连接层2\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    # 前向传播方法\n",
    "    def forward(self, x):\n",
    "        # 卷积与池化\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # 数据展平 Flatten\n",
    "        x = x.view(-1, 32 * 56 * 56) \n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练、测试\n",
    "设置训练参数，划分训练集测试集，训练与评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My device is:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 625/625 [14:34<00:00,  1.40s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for Epoch 1: 0.4587\n",
      "Accuracy: 90.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 625/625 [14:55<00:00,  1.43s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for Epoch 2: 0.2021\n",
      "Accuracy: 90.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 625/625 [14:40<00:00,  1.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for Epoch 3: 0.1647\n",
      "Accuracy: 90.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 625/625 [14:47<00:00,  1.42s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for Epoch 4: 0.1257\n",
      "Accuracy: 90.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 625/625 [14:37<00:00,  1.40s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss for Epoch 5: 0.0855\n",
      "Accuracy: 90.32%\n"
     ]
    }
   ],
   "source": [
    "class Model4Classify:\n",
    "    # 初始化方法\n",
    "    def __init__(self) -> None:\n",
    "        # 任务种类（二分类、五分类），需要手动设置修改\n",
    "        self.num_classes = 2\n",
    "        # 设置device，cuda or cpu\n",
    "        self.setup_device()\n",
    "        # 设置模型训练参数\n",
    "        self.setup_model_parameters()\n",
    "        # 载入数据集\n",
    "        self.setup_dataset()\n",
    "        # 设置数据集分割，得到训练集、测试集\n",
    "        self.setup_dataset_split()\n",
    "        # 设置训练结果存储位置\n",
    "        self.setup_address()\n",
    "        # 设置随机数\n",
    "        self.setup_random_seeds()\n",
    "\n",
    "    # 设置device，cuda or cpu\n",
    "    def setup_device(self):\n",
    "        # 自动选择\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(\"My device is: \", self.device)\n",
    "  \n",
    "    # 设置模型训练参数\n",
    "    def setup_model_parameters(self):  \n",
    "        # 手动设置batch_size和num_epochs    \n",
    "        self.batch_size = 64\n",
    "        self.num_epochs = 5\n",
    "\n",
    "        # 选择模型、损失函数、优化器\n",
    "        self.model = CNN(self.num_classes).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters())\n",
    "    \n",
    "    # 载入数据集\n",
    "    def setup_dataset(self):\n",
    "        # 数据集已经在CustomDataset实例化过程中完成预处理，此处只需载入\n",
    "        self.all_data = dataset\n",
    "\n",
    "    # 数据集分割，得到训练集和测试集\n",
    "    def setup_dataset_split(self):\n",
    "        # 设定分割比例，计算训练集和测试集的大小\n",
    "        total_size = len(self.all_data)\n",
    "        train_ratio = 0.8\n",
    "        test_ratio = 0.2  \n",
    "        train_size = int(total_size * train_ratio)\n",
    "        test_size = total_size - train_size  \n",
    "\n",
    "        # 使用 random_split 进行分割\n",
    "        self.train_dataset, self.test_dataset = random_split(self.all_data, [train_size, test_size])\n",
    "        \n",
    "        # 创建 DataLoader--train_loader and test_loader\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    # 设置训练结果存储位置\n",
    "    def setup_address(self):\n",
    "        # 训练结果\n",
    "        self.result_path = 'result.txt'\n",
    "\n",
    "    # 设置随机数\n",
    "    def setup_random_seeds(self):\n",
    "        # 随机数种子（手动设置）\n",
    "        self.seed = 42\n",
    "        # Python 随机数生成器\n",
    "        random.seed(self.seed)  \n",
    "        # Numpy 随机数生成器\n",
    "        np.random.seed(self.seed)\n",
    "        # PyTorch 随机数生成器\n",
    "        torch.manual_seed(self.seed)   \n",
    "        # PyTorch CUDA 随机数生成器          \n",
    "        torch.cuda.manual_seed(self.seed)       \n",
    "        # PyTorch CUDA（所有GPU）随机数生成器 \n",
    "        torch.cuda.manual_seed_all(self.seed)    \n",
    "        # CUDA确定性算法\n",
    "        torch.backends.cudnn.deterministic = True  \n",
    "        torch.backends.cudnn.benchmark = False     \n",
    "\n",
    "    # 模型训练方法\n",
    "    def train_model(self):\n",
    "        epochs = self.num_epochs\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for images, labels in tqdm(self.train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\"):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                # 梯度清零\n",
    "                self.optimizer.zero_grad()\n",
    "                # 前向传播\n",
    "                outputs = self.model(images)\n",
    "                # 计算损失\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                # 反向传播与优化\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # 累计损失\n",
    "                total_loss += loss.item()\n",
    "            # 计算平均损失并打印\n",
    "            avg_loss = total_loss / len(self.train_loader)\n",
    "            print(f\"Average training loss for Epoch {epoch + 1}: {avg_loss:.4f}\")\n",
    "            # 计算准确率Accuracy以评估模型并打印\n",
    "            accuracy = self.evaluate_model()\n",
    "            print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "            # 在result中写入累计损失、平均损失和准确率\n",
    "            with open(self.result_path, 'a') as result_file:\n",
    "                result_file.write(f'Epoch [{epoch+1}/{epochs}]\\n')\n",
    "                result_file.write(f'Total Loss: {total_loss}, Average Loss: {avg_loss}, Accuracy: {accuracy}\\n')\n",
    "\n",
    "    # 模型评估方法\n",
    "    def evaluate_model(self):\n",
    "        model = self.model\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            # 遍历测试集，无梯度计算\n",
    "            for images, labels in self.test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                # 模型预测\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                # 累计总样本数\n",
    "                total += labels.size(0)\n",
    "                # 累计正确预测数\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        # 计算并返回准确率\n",
    "        accuracy = 100 * correct / total\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "# 实例化Model4Classify，训练模型         \n",
    "model_01 = Model4Classify()\n",
    "model_01.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
